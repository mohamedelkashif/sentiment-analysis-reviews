{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews in reviews1.json = 188\n",
      "Number of positive reviews = 39\n",
      "Number of negative reviews = 130\n",
      "Number of neutral reviews = 19\n",
      "\n",
      "The max values are: \n",
      "Max Ratings.Overall 5.0\n",
      "Max Ratings.Rooms 5\n",
      "Max Ratings.Value 5\n",
      "Max Ratings.Cleanliness 5\n",
      "Max Ratings.Location 5\n",
      "Max Ratings.Sleep Quality 5\n",
      "\n",
      "The min values are: \n",
      "Min Ratings.Overall 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:130: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Ratings.Rooms nan\n",
      "Min Ratings.Value nan\n",
      "Min Ratings.Cleanliness nan\n",
      "Min Ratings.Location nan\n",
      "Min Ratings.Sleep Quality nan\n",
      "                   Author               Date  \\\n",
      "0                 amacwow      April 7, 2012   \n",
      "1            robinhenshaw      April 5, 2012   \n",
      "2             zorro-plata      April 2, 2012   \n",
      "3               judystoks     March 27, 2012   \n",
      "4                  Qwik16     March 23, 2012   \n",
      "5      travelermanPhoenix     March 22, 2012   \n",
      "6                 TXJones     March 15, 2012   \n",
      "7              Franklin J     March 15, 2012   \n",
      "8               winkrob92      March 2, 2012   \n",
      "9          JubilantBeggar  February 26, 2012   \n",
      "10               Lw080212  February 20, 2012   \n",
      "11           maxi_bon2011  February 20, 2012   \n",
      "12              alanadi25  February 12, 2012   \n",
      "13           lillypilly72  February 12, 2012   \n",
      "14                Janieg9   February 8, 2012   \n",
      "15              Triplewin   February 1, 2012   \n",
      "16           Mimielephant   January 30, 2012   \n",
      "17           Globetrekers   January 26, 2012   \n",
      "18             SydneyTash   January 19, 2012   \n",
      "19             DalisuDube   January 16, 2012   \n",
      "20               Dan_H777    January 7, 2012   \n",
      "21           Karleewdwicp  December 29, 2011   \n",
      "22                 Riclau  December 26, 2011   \n",
      "23              Cindy8527  December 25, 2011   \n",
      "24             ozziegirlz  December 16, 2011   \n",
      "25                 dkcoll  December 11, 2011   \n",
      "26         CherylandBrett   December 7, 2011   \n",
      "27               kiwi2403  November 26, 2011   \n",
      "28            Kazoo_Bruce  November 20, 2011   \n",
      "29               status88  November 19, 2011   \n",
      "..                    ...                ...   \n",
      "158           tell_me_how    August 24, 2007   \n",
      "159            Staidthere    August 12, 2007   \n",
      "160           Naturefreak       July 5, 2007   \n",
      "161     travelleralamundo      June 27, 2007   \n",
      "162           Dani_Serres      June 20, 2007   \n",
      "163             mamboking       June 5, 2007   \n",
      "164          Live2Explore      April 2, 2007   \n",
      "165           LittleMissK  February 13, 2007   \n",
      "166        brisbane-chick   January 29, 2007   \n",
      "167                  RexT   October 25, 2006   \n",
      "168             Laurasara   October 11, 2006   \n",
      "169            Ariana&Sam  September 8, 2006   \n",
      "170                chocs1    August 29, 2006   \n",
      "171                Bigcha    August 10, 2006   \n",
      "172        thefamilycoops        May 7, 2006   \n",
      "173                 toela     April 21, 2006   \n",
      "174         Livinginspain      April 4, 2006   \n",
      "175  A TripAdvisor Member      April 4, 2006   \n",
      "176               maugrim     March 18, 2006   \n",
      "177              Marie715  February 16, 2006   \n",
      "178           R0adWarrier   February 7, 2006   \n",
      "179        Florida-Falcon    January 5, 2006   \n",
      "180      Oakhursttraveler       May 12, 2005   \n",
      "181  A TripAdvisor Member  February 16, 2005   \n",
      "182                Wasabi  February 15, 2005   \n",
      "183     MontrealSunseeker   January 29, 2005   \n",
      "184  A TripAdvisor Member   January 23, 2005   \n",
      "185                Noel O  November 20, 2004   \n",
      "186  A TripAdvisor Member   November 9, 2004   \n",
      "187               roam-ID   October 11, 2004   \n",
      "\n",
      "                                               Content  \n",
      "0    Hotel is clean and very close to airport. Staf...  \n",
      "1    Very convenient for LAX (free shuttle). New ve...  \n",
      "2    The thing I like most about Holiday Inn LAX is...  \n",
      "3    We stayed here one night before taking a cruis...  \n",
      "4    This hotel is just minutes away from LAX with ...  \n",
      "5    I stay at this hotel a lot. The staff is nice ...  \n",
      "6    This hotel is good for a one night stay close ...  \n",
      "7    I've been trying to call the hotel for the pas...  \n",
      "8    It's a hit &the miss one week go od another ba...  \n",
      "9    Marginal hotel, but close in proximity to LAX....  \n",
      "10   We stayed in this hotel as we transited to & f...  \n",
      "11   I'd recommend this hotel for a quick stopover ...  \n",
      "12   Check in was quick and easy, our room was big ...  \n",
      "13   I stayed at this hotel for 1 night prior to fl...  \n",
      "14   Concierge and staff were very friendly, room w...  \n",
      "15   Even as I write this I find it hard to describ...  \n",
      "16   Overall, we had an average experience at this ...  \n",
      "17   My wife is an airline employee so we fly stand...  \n",
      "18   After missing a flight, I had to find accomoda...  \n",
      "19   Great Service. Rooms are very nice.Close to LA...  \n",
      "20   We recently(20 Dec 2011) stayed for a night be...  \n",
      "21   I recently stayed at the holiday inn at lax ai...  \n",
      "22   we came back to la to see a sport game and ask...  \n",
      "23   We had two rooms here. One was loud and noisy ...  \n",
      "24   My sister and I chose to stay here overnight b...  \n",
      "25   We booked this hotel as we had an early flight...  \n",
      "26   We have been staying here for 20 years because...  \n",
      "27   We have used this hotel quite a lot of times w...  \n",
      "28   Nice property next to LAX. Recently updated. M...  \n",
      "29   I stayed 3 nights for a business trip. The hot...  \n",
      "..                                                 ...  \n",
      "158  This hotel is in desperate need of an upgrade....  \n",
      "159  My wife and I stayed at the Holday Inn LAX for...  \n",
      "160  This was the worst place we stayed during our ...  \n",
      "161  Got a free night at this hotel courtesy of a m...  \n",
      "162  I stayed there twice in my last trip to LA. Ve...  \n",
      "163  After reading many reviews on Tripadvisor I fi...  \n",
      "164  it was just an average experience for me. Thou...  \n",
      "165  I stayed here with 2 friends in February 2006 ...  \n",
      "166  After reading almost every review on this hote...  \n",
      "167  Stayed here 2 nights; you get pretty much what...  \n",
      "168  My room number was given to a man that I did n...  \n",
      "169  We stayed at this hotel for two nights before ...  \n",
      "170  This hotel is one mile from the airport I stay...  \n",
      "171  We were stuck in LAX overnight due to flight d...  \n",
      "172  We stayed three nights early april, we could n...  \n",
      "173  We stayed at the Holiday Inn Apr 14, for an ea...  \n",
      "174  The staff was nice. It is close to the airport...  \n",
      "175  We stayed here for 1 night courtesy of Northwe...  \n",
      "176  I stayed here on 2 occasions and think that it...  \n",
      "177  I was pleasantly surprised by my one night sta...  \n",
      "178  I was very satisfied. There are bus stops righ...  \n",
      "179  My wife and I stayed at this hotel as part of ...  \n",
      "180  Very convenient to the airport. Clean, big roo...  \n",
      "181  Stayed at this hotel for one night during Janu...  \n",
      "182  Myself and my wife spent 1 night in the hotel....  \n",
      "183  We booked this place on a family vacation in C...  \n",
      "184  We stayed in this motel for 1 night before we ...  \n",
      "185  Very convenient location when you want to drop...  \n",
      "186  Stayed one night with my wife in June 2004. Co...  \n",
      "187  Stayed here on business. Seemed like a decent ...  \n",
      "\n",
      "[188 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "from pandas.io.json import json_normalize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import cross_validation\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "file = \"C:\\\\Users\\\\user\\\\Desktop\\\\semantics.json\"\n",
    "file1 = \"C:\\\\Users\\\\user\\\\Desktop\\\\reviews1.json\"  #reviews1.json\n",
    "df1 = pd.read_json(file1,typ='series')\n",
    "\n",
    "df_rev = json_normalize(df1['Reviews'])\n",
    "df_rev['full_content'] = df_rev['Content'] + '. ' + df_rev['Title']\n",
    "pos = pd.read_json(file,typ='series')\n",
    "\n",
    "newcol = df_rev['full_content']\n",
    "newcol.to_csv('content_reviews.csv',header=False, index=False, encoding='utf-8')\n",
    "\n",
    "df = pd.read_csv('C:\\Users\\user\\Documents\\sentiment-analysis-reviews\\content_reviews.csv',encoding='utf-8', header=None)\n",
    "scores = []\n",
    "\n",
    "for x in df[0]:\n",
    "    sen = x.lower()\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    words = word_tokenize(sen)\n",
    "    \n",
    "    wordsFiltered = []\n",
    "    for w in words:\n",
    "        if w not in stopWords:\n",
    "            wordsFiltered.append(w)\n",
    "    #print wordsFiltered\n",
    "    posScore = 0\n",
    "    negScore = 0\n",
    "    for i in range(0,len(pos['positive'])):\n",
    "        for s in wordsFiltered:\n",
    "            if s in pos['positive'][i]['phrase']:\n",
    "                posScore = posScore+pos['positive'][i]['value']\n",
    "                \n",
    "    for j in range(0,len(pos['negative'])):\n",
    "        for s in wordsFiltered:\n",
    "            if s in pos['negative'][j]['phrase']:\n",
    "                negScore = negScore+pos['negative'][j]['value']\n",
    "                \n",
    "    if posScore > negScore:\n",
    "        scores.append('positive')\n",
    "        \n",
    "    elif posScore < negScore:\n",
    "        scores.append('negative')\n",
    "    else:\n",
    "        scores.append('neutral')\n",
    "        \n",
    "            \n",
    "df['scores'] = scores\n",
    "#df\n",
    "\n",
    "df.to_csv('hotels_scores.csv', header=False, index=False,encoding='utf-8')\n",
    "\n",
    "#After having csv containg reviews and their coresponding sentiment, pass them to ML model to train and get their accuracy\n",
    "\n",
    "#loading file\n",
    "\n",
    "def load_file():\n",
    "    with open('C:\\Users\\user\\Documents\\sentiment-analysis-reviews\\hotels_scores.csv') as csv_file:\n",
    "        reader = csv.reader(csv_file,delimiter=\",\",quotechar='\"')\n",
    "        reader.next()\n",
    "        data =[]\n",
    "        target = []\n",
    "        for row in reader:\n",
    "            if row[0] and row[1]:\n",
    "                data.append(row[0])\n",
    "                target.append(row[1])\n",
    "\n",
    "        return data,target\n",
    "\n",
    "#creating the trem frequency matrix for the dataset\n",
    "def preprocess():\n",
    "    data,target = load_file()\n",
    "    count_vectorizer = CountVectorizer(binary='true')\n",
    "    data = count_vectorizer.fit_transform(data)\n",
    "    tfidf_data = TfidfTransformer(use_idf=False).fit_transform(data)\n",
    "    \n",
    "    return tfidf_data\n",
    "\n",
    "def learning_model(data,target):\n",
    "    # preparing data for split validation. 60% training, 40% test\n",
    "    data_train,data_test,target_train,target_test = cross_validation.train_test_split(data,target,test_size=0.3,random_state=43)\n",
    "    classifier = BernoulliNB().fit(data_train,target_train)\n",
    "    predicted = classifier.predict(data_test)\n",
    "    evaluate_model(target_test,predicted)\n",
    "    \n",
    "\n",
    "def evaluate_model(target_true,target_predicted):\n",
    "    print classification_report(target_true,target_predicted)\n",
    "    print \"The accuracy score is {:.2%}\".format(accuracy_score(target_true,target_predicted))\n",
    "        \n",
    "def main():\n",
    "    data,target = load_file()\n",
    "    tf_idf = preprocess()\n",
    "    learning_model(tf_idf,target)\n",
    "# main()\n",
    "\n",
    "# Some statistics about the reviews:\n",
    "print(\"Number of reviews in reviews1.json = \" + str(len(df.index)))\n",
    "positive_rev = (df['scores'] == 'positive').sum()\n",
    "negative_rev = (df['scores'] == 'negative').sum()\n",
    "neutral_rev = (df['scores'] == 'neutral').sum()\n",
    "print(\"Number of positive reviews =\" + \" \"+str(positive_rev))\n",
    "print(\"Number of negative reviews =\" + \" \"+str(negative_rev))\n",
    "print(\"Number of neutral reviews =\" +\" \"+ str(neutral_rev))\n",
    "\n",
    "df.describe()\n",
    "\n",
    "\n",
    "df_X = pd.read_json(file1,typ='series')\n",
    "df_XX = json_normalize(df_X['Reviews'])\n",
    "\n",
    "\n",
    "df2 = json_normalize(df1['Reviews'])\n",
    "df2 = df2.convert_objects(convert_numeric=True)\n",
    "\n",
    "#mean_ratings = df2.groupby('ReviewID').mean()\n",
    "#min_ratings = df2.groupby('Ratings.Overall').min()\n",
    "#max_ratings = df2.groupby('Ratings.Overall').max()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print ('\\nThe mean values are: ')\n",
    "#print (mean_ratings)\n",
    "\n",
    "#print ('\\nThe min values are: ')\n",
    "#print (min_ratings)\n",
    "\n",
    "#print ('\\nThe max values are: ')\n",
    "#print (max_ratings)\n",
    "\n",
    "\n",
    "print ('\\nThe max values are: ')\n",
    "print (\"Max Ratings.Overall \" + str(max(json_normalize(df1['Reviews'])['Ratings.Overall'])))\n",
    "print (\"Max Ratings.Rooms \" + str(max(json_normalize(df1['Reviews'])['Ratings.Rooms'])))\n",
    "print (\"Max Ratings.Value \" + str(max(json_normalize(df1['Reviews'])['Ratings.Value'])))\n",
    "print (\"Max Ratings.Cleanliness \" + str(max(json_normalize(df1['Reviews'])['Ratings.Cleanliness'])))\n",
    "print (\"Max Ratings.Location \" + str(max(json_normalize(df1['Reviews'])['Ratings.Location'])))\n",
    "print (\"Max Ratings.Sleep Quality \" + str(max(json_normalize(df1['Reviews'])['Ratings.Sleep Quality'])))\n",
    "\n",
    "print ('\\nThe min values are: ')\n",
    "print (\"Min Ratings.Overall \" + str(min(json_normalize(df1['Reviews'])['Ratings.Overall'])))\n",
    "print (\"Min Ratings.Rooms \" + str(min(json_normalize(df1['Reviews'])['Ratings.Rooms'])))\n",
    "print (\"Min Ratings.Value \" + str(min(json_normalize(df1['Reviews'])['Ratings.Value'])))\n",
    "print (\"Min Ratings.Cleanliness \" + str(min(json_normalize(df1['Reviews'])['Ratings.Cleanliness'])))\n",
    "print (\"Min Ratings.Location \" + str(min(json_normalize(dfm['Reviews'])['Ratings.Location'])))\n",
    "print (\"Min Ratings.Sleep Quality \" + str(min(json_normalize(df1['Reviews'])['Ratings.Sleep Quality'])))\n",
    "\n",
    "\n",
    "#Authors and their comments ordered by date of comment \n",
    "review_comments = pd.DataFrame(df1['Reviews'], columns=['Author', 'Date', 'Content'])\n",
    "review_comments.set_index(['Author'])\n",
    "print (review_comments)\n",
    "# json_normalize(df1['Reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
